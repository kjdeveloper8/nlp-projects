{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc110485-7a51-4fb4-b77d-b3798bdf2abd",
   "metadata": {},
   "source": [
    "## Transformer \n",
    "\n",
    "This notebook is for understanding transformer architecture.\n",
    "\n",
    "For more detail see: [d2l: Transformer Architecture](https://d2l.ai/chapter_attention-mechanisms-and-transformers/transformer.html)\n",
    "\n",
    "\n",
    "- Transformer Architecture\n",
    "  - Embeddings \n",
    "  - Positional FFN\n",
    "  - LayerNorm\n",
    "  - AddNorm\n",
    "  - PositionalEncoding\n",
    "  - Multihead Attention\n",
    "  - TransformerEncoderBlock(single layer)\n",
    "  - TransformerEncoder\n",
    "  - TransformerDecoderBlock\n",
    "  - TransformerDecoder\n",
    "  - Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2772fc-53f1-4ba5-b2da-e8e1dc336a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39681a82-e7d9-410a-b7cb-b2671a17ded2",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f594f7b2-7785-4c86-a0af-fea5202fb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        \"\"\" Embedding class to convert a word into embedding space.\"\"\"\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim) # vocab_size x embed_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.embed(x) * sqrt(self.embed_dim)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f749d22b-bf62-43c3-8768-45f58970479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(\n",
       "  (embed): Embedding(100, 512)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = Embedding(100, 512)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "564b501c-ed8d-42ed-a330-c26bbb96d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_shape(a, shape):\n",
    "    assert a.shape == shape, f'tensor\\'s shape {a.shape} != expected shape {shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693168fd-eeab-4f16-b640-25c2ef00718e",
   "metadata": {},
   "source": [
    "#### Positional FFN\n",
    "\n",
    "PFFN transforms the representation at sequence positions using the same MLP(Multi layer perceptron). \n",
    "\n",
    "Here, input X with shape (batch size, number of time steps or sequence length in tokens, number of hidden units or feature dimension) will be transformed by a two-layer MLP into an output tensor of shape (batch size, number of time steps, ffn_num_outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aedea935-cc84-4271-9f02-c5065385b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec71e8e-6355-4bec-8a7d-5537bb542992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module): \n",
    "    \"\"\"The positionwise feed-forward network.\"\"\"\n",
    "    def __init__(self, ffn_num_hiddens, ffn_num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        # As we want to initialize weights later on we will use Lazy version \n",
    "        self.dense1 = nn.LazyLinear(ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.LazyLinear(ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "561c784c-7399-4d52-8cda-a02c96417cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PositionWiseFFN(\n",
       "  (dense1): LazyLinear(in_features=0, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dense2): LazyLinear(in_features=0, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = PositionWiseFFN(4, 8)\n",
    "ffn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ea398ba-4f45-4d33-8cf7-29abe2b12074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4662, -0.2785, -0.1906, -0.0019, -0.0851,  0.4234, -0.0755,  0.2674],\n",
       "        [ 0.4662, -0.2785, -0.1906, -0.0019, -0.0851,  0.4234, -0.0755,  0.2674],\n",
       "        [ 0.4662, -0.2785, -0.1906, -0.0019, -0.0851,  0.4234, -0.0755,  0.2674]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: to see tensors in PFFN\n",
    "# As the same MLP transforms at all the positions\n",
    "# when the inputs at all these positions are the same\n",
    "# their outputs are also identical\n",
    "ffn(torch.ones((2, 3, 4)))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88a55e-bace-4eef-b1b5-1cb5e9781dcd",
   "metadata": {},
   "source": [
    "#### Layer Normalization\n",
    "\n",
    "As we want to normalize each feature dim, LayerNorm is more suitable as it applies per-element scale and bias which makes it scale independence and batch size independence.\n",
    "Unlike Batch Normalization which applies scalar scale and bias for each entire channel/plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44b1e253-bf01-4a31-a9fc-bd8bcc9d6492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -1.0000],\n",
       "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln = nn.LayerNorm(2)\n",
    "X = torch.tensor([[10, 2], [2, 5]], dtype=torch.float32)\n",
    "ln(X) # compute mean and var of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d11a201f-4bf8-4627-9bdc-1b133fb6486f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1380, -1.9568,  0.5463,  1.5227,  0.4377,  0.5928,  0.7892,  0.0591,\n",
       "        -1.2869, -0.8421], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, sentence_length, embedding_dim = 20, 5, 10\n",
    "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "layer_norm(embedding[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e5255-ee28-489f-adc3-650971c1dccf",
   "metadata": {},
   "source": [
    "#### AddNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386629e2-9016-425b-af8d-42d55e03530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"The residual connection followed by layer normalization.\"\"\"\n",
    "    def __init__(self, norm_shape, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(norm_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eb6ef39-f94e-453b-a07f-e16b0bae56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_norm = AddNorm(4, 0.5)\n",
    "shape = (2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35c82bfa-c0a3-4efd-9e8c-a620d5a4783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_shape(add_norm(torch.ones(shape), torch.ones(shape)), shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f73862-ee71-421c-a8bb-d4257234052c",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93a7df04-be37-4a20-99ba-8596347a01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module): \n",
    "    \"\"\"Basic scaled dot product attention.\"\"\"\n",
    "    def __init__(self, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96285b-8a78-4109-99b1-9287ecac4aa2",
   "metadata": {},
   "source": [
    "#### MultiHead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a135b19-1deb-4148-aeca-b5cb247a3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-head attention.\"\"\"\n",
    "    def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = Attention(dropout)\n",
    "        self.W_q = nn.LazyLinear(num_hiddens, bias=bias)\n",
    "        self.W_k = nn.LazyLinear(num_hiddens, bias=bias)\n",
    "        self.W_v = nn.LazyLinear(num_hiddens, bias=bias)\n",
    "        self.W_o = nn.LazyLinear(num_hiddens, bias=bias)\n",
    "\n",
    "    \n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries = self.transpose_qkv(self.W_q(queries)) # (b*h, n_q, h)\n",
    "        keys = self.transpose_qkv(self.W_k(keys))       # (b*h, n_kv, h)\n",
    "        values = self.transpose_qkv(self.W_v(values))   # (b*h, n_kv, h)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        output = self.attention(queries, keys, values, valid_lens) # (b*h, n_q, h)\n",
    "        \n",
    "        output_concat = self.transpose_output(output) # (b, n_q, n_h)\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f09e46c4-712b-48da-95ca-4803837d7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):\n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "946133bb-0553-4673-9a08-a0e5305893d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultiHeadAttention)\n",
    "def transpose_qkv(self, X):\n",
    "    \"\"\"Transposition for multiple attention heads.\"\"\"\n",
    "    # input X: (b, n_q or n_kv, h)\n",
    "    # output: (b, n_q or n_kv, h, h)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], self.num_heads, -1)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7279d926-b5d0-4c81-8223-23ba5af62272",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultiHeadAttention)\n",
    "def transpose_output(self, X):\n",
    "    \"\"\"Reverse the operation of transpose_qkv.\"\"\"\n",
    "    X = X.reshape(-1, self.num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf38cf3-3be8-4ef2-bbc2-a45350463992",
   "metadata": {},
   "source": [
    "#### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24a18a45-599e-4aab-bd47-15f665e0aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9b2ac-e732-4b0c-9027-af09280c58a3",
   "metadata": {},
   "source": [
    "#### Transformer Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2689683c-9c27-4cc0-a012-4dc902b45e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    \"\"\"The Transformer encoder block.\"\"\"\n",
    "    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout,\n",
    "                 use_bias=False):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(num_hiddens, num_heads, dropout, use_bias)\n",
    "        self.addnorm1 = AddNorm(num_hiddens, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(num_hiddens, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens = torch.tensor([3, 2])):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63f34a7b-a668-4b32-8787-8d1c06a77795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoderBlock(\n",
       "  (attention): MultiHeadAttention(\n",
       "    (attention): Attention(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (W_q): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "    (W_k): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "    (W_v): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "    (W_o): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "  )\n",
       "  (addnorm1): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (ffn): PositionWiseFFN(\n",
       "    (dense1): LazyLinear(in_features=0, out_features=48, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dense2): LazyLinear(in_features=0, out_features=24, bias=True)\n",
       "  )\n",
       "  (addnorm2): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((2, 100, 24))\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "encoder_blk = TransformerEncoderBlock(24, 48, 8, 0.5)\n",
    "encoder_blk.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4ca9023-172c-472f-a952-2bac40336a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"The Transformer encoder.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout, use_bias=False):\n",
    "        super().__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_blks):\n",
    "            self.blks.add_module(\"block\"+str(i), TransformerEncoderBlock(\n",
    "                num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens = torch.tensor([3, 2])):\n",
    "        # Since positional encoding values are between -1 and 1, the embedding\n",
    "        # values are multiplied by the square root of the embedding dimension\n",
    "        # to rescale before they are summed up\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc99ae-56fd-4664-b357-3971e3826d07",
   "metadata": {},
   "source": [
    "#### Transformer Decoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef05952e-4c1a-4983-945a-c1fe6f022008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderBlock(nn.Module):\n",
    "    # i-th block \n",
    "    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout, i):\n",
    "        super().__init__()\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(num_hiddens, dropout)\n",
    "        self.attention2 = MultiHeadAttention(num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(num_hiddens, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm(num_hiddens, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), dim=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # Shape of dec_valid_lens: (batch_size, num_steps), where every\n",
    "            # row is [1, 2, ..., num_steps]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "        # Self-attention\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # Encoder-decoder attention\n",
    "        # (batch_size, num_steps, num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed6be70f-ab9c-4f2a-a22d-9b1daacb470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n",
    "                 num_blks, dropout):\n",
    "        super().__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_blks = num_blks\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_blks):\n",
    "            self.blks.add_module(\"block\"+str(i), TransformerDecoderBlock(\n",
    "                num_hiddens, ffn_num_hiddens, num_heads, dropout, i))\n",
    "        self.dense = nn.LazyLinear(vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_blks]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            # Decoder self-attention weights\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            # Encoder-decoder attention weights\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe358864-a69d-4458-9a6b-72b0c57333f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(200, 24, 48, 8, 2, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "defb4cdb-df47-4a07-b9d2-e11ee4ee23e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (embedding): Embedding(200, 24)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (blks): Sequential(\n",
       "    (block0): TransformerEncoderBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (attention): Attention(\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (W_q): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "        (W_k): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "        (W_v): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "        (W_o): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "      )\n",
       "      (addnorm1): AddNorm(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (ln): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): PositionWiseFFN(\n",
       "        (dense1): LazyLinear(in_features=0, out_features=48, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dense2): LazyLinear(in_features=0, out_features=24, bias=True)\n",
       "      )\n",
       "      (addnorm2): AddNorm(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (ln): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block1): TransformerEncoderBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (attention): Attention(\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (W_q): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "        (W_k): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "        (W_v): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "        (W_o): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "      )\n",
       "      (addnorm1): AddNorm(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (ln): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ffn): PositionWiseFFN(\n",
       "        (dense1): LazyLinear(in_features=0, out_features=48, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dense2): LazyLinear(in_features=0, out_features=24, bias=True)\n",
       "      )\n",
       "      (addnorm2): AddNorm(\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (ln): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c479d846-9cd2-472c-a7e7-838772ac424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = TransformerDecoderBlock(24, 48, 8, 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a2ed45d-cfc7-44e5-b841-568ddae69266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoderBlock(\n",
       "  (attention1): MultiHeadAttention(\n",
       "    (attention): Attention(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (W_q): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "    (W_k): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "    (W_v): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "    (W_o): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "  )\n",
       "  (addnorm1): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (attention2): MultiHeadAttention(\n",
       "    (attention): Attention(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (W_q): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "    (W_k): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "    (W_v): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "    (W_o): LazyLinear(in_features=0, out_features=24, bias=False)\n",
       "  )\n",
       "  (addnorm2): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (ffn): PositionWiseFFN(\n",
       "    (dense1): LazyLinear(in_features=0, out_features=48, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dense2): LazyLinear(in_features=0, out_features=24, bias=True)\n",
       "  )\n",
       "  (addnorm3): AddNorm(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (ln): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22672b1e-8194-4d3d-b5ff-1bc42205c1c6",
   "metadata": {},
   "source": [
    "#### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a32dd7cc-b2a0-49e6-b1e1-f6b1c76cece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed_dim,\n",
    "                 src_vocab_size,\n",
    "                 target_vocab_size,\n",
    "                 ffn,\n",
    "                 num_blocks=6,\n",
    "                 heads=8,\n",
    "                 dropout=0.2):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.encoder = TransformerEncoder(\n",
    "                        vocab_size=src_vocab_size, \n",
    "                        num_hiddens=embed_dim, \n",
    "                        ffn_num_hiddens=ffn, \n",
    "                        num_heads=heads,\n",
    "                        num_blks=num_blocks, \n",
    "                        dropout=dropout)\n",
    "        self.decoder = TransformerDecoder(\n",
    "                        vocab_size=target_vocab_size, \n",
    "                        num_hiddens=embed_dim, \n",
    "                        ffn_num_hiddens=ffn, \n",
    "                        num_heads=heads, \n",
    "                        num_blks=num_blocks, \n",
    "                        dropout=dropout)\n",
    "        self.fc_out = nn.Linear(embed_dim, target_vocab_size)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        # returns the lower triangular part of matrix filled with ones\n",
    "        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
    "            batch_size, 1, trg_len, trg_len\n",
    "        )\n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        trg_mask = self.make_trg_mask(target)\n",
    "        enc_out = self.encoder(source)\n",
    "        outputs = self.decoder(target, enc_out, trg_mask)\n",
    "        output = F.softmax(self.fc_out(outputs), dim=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35324bd2-494e-4eef-9880-a0d51860d0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embedding): Embedding(12, 512)\n",
      "    (pos_encoding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (blks): Sequential(\n",
      "      (block0): TransformerEncoderBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block1): TransformerEncoderBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block2): TransformerEncoderBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block3): TransformerEncoderBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block4): TransformerEncoderBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block5): TransformerEncoderBlock(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embedding): Embedding(12, 512)\n",
      "    (pos_encoding): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (blks): Sequential(\n",
      "      (block0): TransformerDecoderBlock(\n",
      "        (attention1): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (attention2): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm3): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block1): TransformerDecoderBlock(\n",
      "        (attention1): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (attention2): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm3): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block2): TransformerDecoderBlock(\n",
      "        (attention1): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (attention2): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm3): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block3): TransformerDecoderBlock(\n",
      "        (attention1): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (attention2): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm3): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block4): TransformerDecoderBlock(\n",
      "        (attention1): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (attention2): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm3): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (block5): TransformerDecoderBlock(\n",
      "        (attention1): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm1): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (attention2): MultiHeadAttention(\n",
      "          (attention): Attention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (W_q): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_k): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_v): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "          (W_o): LazyLinear(in_features=0, out_features=512, bias=False)\n",
      "        )\n",
      "        (addnorm2): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (ffn): PositionWiseFFN(\n",
      "          (dense1): LazyLinear(in_features=0, out_features=22, bias=True)\n",
      "          (relu): ReLU()\n",
      "          (dense2): LazyLinear(in_features=0, out_features=512, bias=True)\n",
      "        )\n",
      "        (addnorm3): AddNorm(\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dense): LazyLinear(in_features=0, out_features=12, bias=True)\n",
      "  )\n",
      "  (fc_out): Linear(in_features=512, out_features=12, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# test example\n",
    "model = Transformer(embed_dim=512,\n",
    "                    src_vocab_size=12,\n",
    "                    target_vocab_size=12,\n",
    "                    ffn=22,\n",
    "                    num_blocks=6,\n",
    "                    heads=8)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249e0ee-6392-4b48-b1cf-b5a416ca02f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
